{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://pbs.twimg.com/profile_images/928987025403006976/_1jMEtK9_400x400.jpg\" alt=\"drawing\" width=\"200px\"/>\n",
    "\n",
    "<h2 style=\"text-align: center; margin-top: .5em\"> \n",
    "    [Universidade Federal de Campina Grande - UFCG](http://www.ufcg.edu.br/) \n",
    "</h2>\n",
    "<h2 style=\"text-align: center; margin-top: .5em\">  \n",
    "    [Departamento de Sistemas e Computação](http://www.computacao.ufcg.edu.br/) \n",
    "</h2>\n",
    "\n",
    "<div style=\"width: 35em; margin: auto; margin-top: 1em\">\n",
    "<h4 style=\"margin-top: .5em\"> Disciplina: [Compiladores](http://www.dsc.ufcg.edu.br/~franklin/disciplinas/2018-1/Compiladores/) </h4>\n",
    "<h4 style=\"margin-top: .5em\"> Professor: [Franklin Ramalho](http://www.dsc.ufcg.edu.br/~franklin/pp/) </h4>\n",
    "<h5 style=\"font-style: normal; margin-top: .5em\"> Alunos: </h5>\n",
    "- [Paulo Sérgio]( mailto:paulo.araujo@ccc.ufcg.edu.br )\n",
    "- [Lucas Diniz]( mailto:d@ccc.ufcg.edu.br )\n",
    "- [Felipe ?]( mailto:f@ccc.ufcg.edu.br )\n",
    "</div>\n",
    "---\n",
    "\n",
    "##### Fases da construção de um compilador \n",
    "Para construirmos um compilador que traduza código GO para Assembly temos que atender as etapas clássicas na construção de um compilador, sendo estas: \n",
    "    1. Análise Léxica \n",
    "    2. Análise Sintática\n",
    "    3. Análise Semântica \n",
    "    \n",
    "### 1. Análise Léxica\n",
    "\n",
    "Para fazer a análise léxica usaremos a ferramenta [JFLEX](http://jflex.de), que é um analisador léxico escrito em java. O JFLEX utiliza um arquivo de entrada que especifíca a estrutura da linguagem. Um manual sobre JFLEX e como entregar com o CUP pode ser encontrado no seguinte endereço http://jflex.de/manual.pdf\n",
    "\n",
    "TO-DO // REFACTOR TUDO daqui pra baixo. \n",
    "\n",
    "##### Como ligar CUP com o projeto. \n",
    "```java\n",
    "import java_cup.runtime.*;\n",
    "import cup.sym; //<< código customizado?\n",
    "\n",
    "%% \n",
    "%cup\n",
    "%cupdebug\n",
    "\n",
    "%{\n",
    "       \n",
    "       private Symbol symbol(int type) {\n",
    "           return new Symbol(type, yyline, yycolumn);\n",
    "          }\n",
    "       \n",
    "        private Symbol symbol(int type, Object val) {\n",
    "           return new Symbol(type, yyline, yycolumn, val);\n",
    "          }\n",
    "          \n",
    "%}\n",
    "%% \n",
    "   ...\n",
    "   {Numero}+{IS}?                            { return symbol(sym.CONSTANT, new String(yytext())); }\n",
    "\n",
    "```\n",
    "\n",
    "Isso deveria gerar uma saída que vai será o parser da linguagem depois. \n",
    "\n",
    "Links:\n",
    "\n",
    "    https://johnidm.gitbooks.io/compiladores-para-humanos/content/part1/lexical-analysis.html\n",
    "\n",
    "    https://johnidm.gitbooks.io/compiladores-para-humanos/content/part2/building-the-first-lexical-analyzer-with-JFlex.html \n",
    "\n",
    "\n",
    "##### Executando a Análise Léxica \n",
    "\n",
    "Abaixo é utilizada a função popen de python que executa um comando e retorna um objeto com informações sobre a execução do comando. \n",
    "\n",
    "O código é claro: \n",
    "    1. As regras léxicas são passadas para o JFLEX\n",
    "    2. Ele cria um DFA (Lexer.java) que nos ajudará a processar os tokens da linguagem.\n",
    "    3. O código fonte é passado para o reconhecedor léxico(Lexer) que imprime os valores casados.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Criação de Lexer.java\n",
    "\n",
    "Para criação do Análisador Léxico, passaremos as regras da linguagem para o Jflex que ira produzir nosso analisador. Em um arquivo Lexer.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading \"src\\flex\\rules.flex\"\n",
      "\n",
      "Warning : Macro \"letter\" has been declared but never used.\n",
      "\n",
      "Warning : Macro \"comment\" has been declared but never used.\n",
      "Constructing NFA : 530 states in NFA\n",
      "Converting NFA to DFA : \n",
      "........................................................................................................................................................................................................................\n",
      "218 states before minimization, 114 states in minimized DFA\n",
      "Old file \"src\\flex\\Lexer.java\" saved as \"src\\flex\\Lexer.java~\"\n",
      "Writing code to \"src\\flex\\Lexer.java\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os import popen\n",
    "print(popen('java -jar lib/jflex-1.6.1.jar src/flex/rules.flex').read()) # Cria um Lexer das regras da análise léxica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Alimentação do Lexer Padrão com código fonte\n",
    "\n",
    "Para garantir que estamos indo na direção correta podemos testar nosso analisador léxico contra uma entrada que contém um erro léxico e ver qual o seu comportamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(popen('javac src/flex/Lexer.java').read()) # Compila o Lexer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found inline comment: simplest possible program\n",
      "\n",
      "Found keyword: package\n",
      "Found identifier: main\n",
      "Found keyword: func\n",
      "Found identifier: main\n",
      "Found operator/punctuation: (\n",
      "Found operator/punctuation: )\n",
      "Found operator/punctuation: {\n",
      "Found identifier: println\n",
      "Found operator/punctuation: (\n",
      "Found string literal: \"Hello World!\"\n",
      "Found operator/punctuation: )\n",
      "Found operator/punctuation: }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(popen('java -cp ./src flex.Lexer test/input/00{0}.go'.format(1)).read()) \n",
    "\n",
    "\n",
    "#for i in range(1, 10):\n",
    "#   print(popen('java -cp ./src flex.Lexer test/input/00{0}.go'.format(i)).read()) # utiliza o Lexer compilado para análisar os tokens encontrados no programa fonte\n",
    "#    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
